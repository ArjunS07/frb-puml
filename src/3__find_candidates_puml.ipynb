{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tns_name</th>\n",
       "      <th>previous_name</th>\n",
       "      <th>repeater_name</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>gl</th>\n",
       "      <th>gb</th>\n",
       "      <th>exp_up</th>\n",
       "      <th>exp_low</th>\n",
       "      <th>bonsai_snr</th>\n",
       "      <th>bonsai_dm</th>\n",
       "      <th>snr_fitb</th>\n",
       "      <th>dm_fitb</th>\n",
       "      <th>dm_exc_ne2001</th>\n",
       "      <th>dm_exc_ymw16</th>\n",
       "      <th>bc_width</th>\n",
       "      <th>scat_time</th>\n",
       "      <th>flux</th>\n",
       "      <th>fluence</th>\n",
       "      <th>sub_num</th>\n",
       "      <th>width_fitb</th>\n",
       "      <th>sp_idx</th>\n",
       "      <th>sp_run</th>\n",
       "      <th>high_freq</th>\n",
       "      <th>low_freq</th>\n",
       "      <th>peak_freq</th>\n",
       "      <th>chi_sq</th>\n",
       "      <th>dof</th>\n",
       "      <th>flag_frac</th>\n",
       "      <th>excluded_flag</th>\n",
       "      <th>previous_rp_name</th>\n",
       "      <th>is_repeater</th>\n",
       "      <th>redshift</th>\n",
       "      <th>fre_width</th>\n",
       "      <th>fre_width_ob</th>\n",
       "      <th>in_duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>T_B</th>\n",
       "      <th>log_dm_fitb</th>\n",
       "      <th>log_bonsai_dm</th>\n",
       "      <th>log_dm_exc_ne2001</th>\n",
       "      <th>log_dm_exc_ymw16</th>\n",
       "      <th>log_bc_width</th>\n",
       "      <th>log_scat_time</th>\n",
       "      <th>log_flux</th>\n",
       "      <th>log_fluence</th>\n",
       "      <th>log_width_fitb</th>\n",
       "      <th>log_high_freq</th>\n",
       "      <th>log_low_freq</th>\n",
       "      <th>log_peak_freq</th>\n",
       "      <th>log_fre_width</th>\n",
       "      <th>log_redshift</th>\n",
       "      <th>log_in_duration</th>\n",
       "      <th>log_energy</th>\n",
       "      <th>log_luminosity</th>\n",
       "      <th>log_T_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB20180725A</td>\n",
       "      <td>180725.J0613+67</td>\n",
       "      <td>-9999</td>\n",
       "      <td>93.42</td>\n",
       "      <td>67.07</td>\n",
       "      <td>147.29</td>\n",
       "      <td>21.29</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>716.6</td>\n",
       "      <td>33.2</td>\n",
       "      <td>715.80930</td>\n",
       "      <td>644.2</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>38.20</td>\n",
       "      <td>-45.80</td>\n",
       "      <td>760.1</td>\n",
       "      <td>485.3</td>\n",
       "      <td>607.4</td>\n",
       "      <td>371857.954</td>\n",
       "      <td>371481</td>\n",
       "      <td>0.403</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640740</td>\n",
       "      <td>450.875425</td>\n",
       "      <td>274.8</td>\n",
       "      <td>0.180406</td>\n",
       "      <td>2.827944e+40</td>\n",
       "      <td>1.923870e+43</td>\n",
       "      <td>5.515622e+35</td>\n",
       "      <td>2.854797</td>\n",
       "      <td>2.855277</td>\n",
       "      <td>2.809021</td>\n",
       "      <td>2.803047</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-2.958607</td>\n",
       "      <td>0.230449</td>\n",
       "      <td>0.612784</td>\n",
       "      <td>-3.528708</td>\n",
       "      <td>2.880871</td>\n",
       "      <td>2.686010</td>\n",
       "      <td>2.783475</td>\n",
       "      <td>2.654057</td>\n",
       "      <td>-0.193318</td>\n",
       "      <td>-0.743748</td>\n",
       "      <td>40.451471</td>\n",
       "      <td>43.284176</td>\n",
       "      <td>35.741595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRB20180727A</td>\n",
       "      <td>180727.J1311+26</td>\n",
       "      <td>-9999</td>\n",
       "      <td>197.72</td>\n",
       "      <td>26.42</td>\n",
       "      <td>24.76</td>\n",
       "      <td>85.60</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>642.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>642.13400</td>\n",
       "      <td>620.9</td>\n",
       "      <td>622.4</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>3.80</td>\n",
       "      <td>-9.20</td>\n",
       "      <td>800.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>493.3</td>\n",
       "      <td>382969.318</td>\n",
       "      <td>381818</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614818</td>\n",
       "      <td>645.927163</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.860778</td>\n",
       "      <td>1.189571e+40</td>\n",
       "      <td>4.823143e+42</td>\n",
       "      <td>2.622746e+35</td>\n",
       "      <td>2.807626</td>\n",
       "      <td>2.807603</td>\n",
       "      <td>2.793022</td>\n",
       "      <td>2.794070</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-2.769551</td>\n",
       "      <td>-0.236572</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>-2.856985</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.693111</td>\n",
       "      <td>2.810184</td>\n",
       "      <td>-0.211253</td>\n",
       "      <td>-0.065109</td>\n",
       "      <td>40.075391</td>\n",
       "      <td>42.683330</td>\n",
       "      <td>35.418756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRB20180729A</td>\n",
       "      <td>180729.J1316+55</td>\n",
       "      <td>-9999</td>\n",
       "      <td>199.40</td>\n",
       "      <td>55.58</td>\n",
       "      <td>115.26</td>\n",
       "      <td>61.16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>108.4</td>\n",
       "      <td>206.6</td>\n",
       "      <td>109.59418</td>\n",
       "      <td>78.8</td>\n",
       "      <td>86.8</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>11.70</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>16.46</td>\n",
       "      <td>-30.21</td>\n",
       "      <td>692.7</td>\n",
       "      <td>400.2</td>\n",
       "      <td>525.6</td>\n",
       "      <td>264732.041</td>\n",
       "      <td>186953</td>\n",
       "      <td>0.399</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>293.157605</td>\n",
       "      <td>292.5</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>1.070358e+36</td>\n",
       "      <td>7.383140e+38</td>\n",
       "      <td>4.845901e+32</td>\n",
       "      <td>2.039787</td>\n",
       "      <td>2.035029</td>\n",
       "      <td>1.896526</td>\n",
       "      <td>1.938520</td>\n",
       "      <td>-3.008774</td>\n",
       "      <td>-3.802995</td>\n",
       "      <td>1.068186</td>\n",
       "      <td>1.230449</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.840545</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.720655</td>\n",
       "      <td>2.467101</td>\n",
       "      <td>-2.648161</td>\n",
       "      <td>-1.000975</td>\n",
       "      <td>36.029529</td>\n",
       "      <td>38.868241</td>\n",
       "      <td>32.685375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRB20180729B</td>\n",
       "      <td>180729.J0558+56</td>\n",
       "      <td>-9999</td>\n",
       "      <td>89.93</td>\n",
       "      <td>56.50</td>\n",
       "      <td>156.90</td>\n",
       "      <td>15.68</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>318.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>317.22350</td>\n",
       "      <td>223.2</td>\n",
       "      <td>198.8</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>14.50</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>800.2</td>\n",
       "      <td>441.8</td>\n",
       "      <td>657.5</td>\n",
       "      <td>425139.488</td>\n",
       "      <td>421337</td>\n",
       "      <td>0.323</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157566</td>\n",
       "      <td>414.871625</td>\n",
       "      <td>358.4</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>4.966122e+38</td>\n",
       "      <td>4.407270e+41</td>\n",
       "      <td>3.166148e+34</td>\n",
       "      <td>2.501365</td>\n",
       "      <td>2.503246</td>\n",
       "      <td>2.348694</td>\n",
       "      <td>2.298416</td>\n",
       "      <td>-2.705534</td>\n",
       "      <td>-3.180456</td>\n",
       "      <td>-0.036212</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>-3.503070</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.645226</td>\n",
       "      <td>2.817896</td>\n",
       "      <td>2.617914</td>\n",
       "      <td>-0.802538</td>\n",
       "      <td>-0.566616</td>\n",
       "      <td>38.696017</td>\n",
       "      <td>41.644170</td>\n",
       "      <td>34.500531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRB20180730A</td>\n",
       "      <td>180730.J0353+87</td>\n",
       "      <td>-9999</td>\n",
       "      <td>57.39</td>\n",
       "      <td>87.19</td>\n",
       "      <td>125.11</td>\n",
       "      <td>25.11</td>\n",
       "      <td>270.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>849.2</td>\n",
       "      <td>89.8</td>\n",
       "      <td>848.90410</td>\n",
       "      <td>789.7</td>\n",
       "      <td>790.5</td>\n",
       "      <td>0.00492</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>5.20</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>4.27</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>759.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>483.5</td>\n",
       "      <td>429165.844</td>\n",
       "      <td>417689</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>647.063272</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.259653</td>\n",
       "      <td>2.335510e+41</td>\n",
       "      <td>8.107252e+43</td>\n",
       "      <td>1.508095e+36</td>\n",
       "      <td>2.928859</td>\n",
       "      <td>2.929010</td>\n",
       "      <td>2.897462</td>\n",
       "      <td>2.897902</td>\n",
       "      <td>-2.308035</td>\n",
       "      <td>-2.683401</td>\n",
       "      <td>0.716003</td>\n",
       "      <td>1.431364</td>\n",
       "      <td>-3.329754</td>\n",
       "      <td>2.880356</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.684396</td>\n",
       "      <td>2.810947</td>\n",
       "      <td>-0.095607</td>\n",
       "      <td>-0.585606</td>\n",
       "      <td>41.368382</td>\n",
       "      <td>43.908874</td>\n",
       "      <td>36.178429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>FRB20190701A</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>277.47</td>\n",
       "      <td>59.04</td>\n",
       "      <td>88.29</td>\n",
       "      <td>25.72</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>635.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>637.09340</td>\n",
       "      <td>582.8</td>\n",
       "      <td>587.8</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>3.30</td>\n",
       "      <td>800.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>800.2</td>\n",
       "      <td>341779.300</td>\n",
       "      <td>341690</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.572362</td>\n",
       "      <td>628.944866</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.386679</td>\n",
       "      <td>1.226913e+40</td>\n",
       "      <td>1.429842e+43</td>\n",
       "      <td>4.195023e+35</td>\n",
       "      <td>2.804203</td>\n",
       "      <td>2.803252</td>\n",
       "      <td>2.765520</td>\n",
       "      <td>2.769230</td>\n",
       "      <td>-2.705534</td>\n",
       "      <td>-3.142668</td>\n",
       "      <td>0.100371</td>\n",
       "      <td>0.230449</td>\n",
       "      <td>-3.216096</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.798613</td>\n",
       "      <td>-0.242329</td>\n",
       "      <td>-0.412649</td>\n",
       "      <td>40.088814</td>\n",
       "      <td>43.155288</td>\n",
       "      <td>35.622734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>FRB20190701B</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>302.93</td>\n",
       "      <td>80.18</td>\n",
       "      <td>112.88</td>\n",
       "      <td>23.40</td>\n",
       "      <td>69.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>748.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>749.11400</td>\n",
       "      <td>687.6</td>\n",
       "      <td>688.1</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>3.90</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>732.8</td>\n",
       "      <td>400.2</td>\n",
       "      <td>471.5</td>\n",
       "      <td>329229.311</td>\n",
       "      <td>330137</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688973</td>\n",
       "      <td>561.752466</td>\n",
       "      <td>332.6</td>\n",
       "      <td>0.373008</td>\n",
       "      <td>1.178856e+40</td>\n",
       "      <td>1.152717e+43</td>\n",
       "      <td>6.863375e+35</td>\n",
       "      <td>2.874548</td>\n",
       "      <td>2.874424</td>\n",
       "      <td>2.837336</td>\n",
       "      <td>2.837652</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-3.468521</td>\n",
       "      <td>0.041393</td>\n",
       "      <td>0.278754</td>\n",
       "      <td>-3.200659</td>\n",
       "      <td>2.864985</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.673482</td>\n",
       "      <td>2.749545</td>\n",
       "      <td>-0.161798</td>\n",
       "      <td>-0.428282</td>\n",
       "      <td>40.071461</td>\n",
       "      <td>43.061723</td>\n",
       "      <td>35.836538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>FRB20190701C</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>96.36</td>\n",
       "      <td>81.63</td>\n",
       "      <td>132.18</td>\n",
       "      <td>25.88</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>972.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>974.19500</td>\n",
       "      <td>915.8</td>\n",
       "      <td>916.6</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>46.20</td>\n",
       "      <td>-211.00</td>\n",
       "      <td>495.5</td>\n",
       "      <td>402.2</td>\n",
       "      <td>446.4</td>\n",
       "      <td>285697.192</td>\n",
       "      <td>286362</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943004</td>\n",
       "      <td>181.282298</td>\n",
       "      <td>93.3</td>\n",
       "      <td>0.741120</td>\n",
       "      <td>2.752633e+40</td>\n",
       "      <td>1.882629e+43</td>\n",
       "      <td>2.574619e+36</td>\n",
       "      <td>2.988646</td>\n",
       "      <td>2.987711</td>\n",
       "      <td>2.961801</td>\n",
       "      <td>2.962180</td>\n",
       "      <td>-2.705534</td>\n",
       "      <td>-2.744727</td>\n",
       "      <td>-0.055517</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>-2.841638</td>\n",
       "      <td>2.695044</td>\n",
       "      <td>2.604442</td>\n",
       "      <td>2.649724</td>\n",
       "      <td>2.258355</td>\n",
       "      <td>-0.025486</td>\n",
       "      <td>-0.130111</td>\n",
       "      <td>40.439748</td>\n",
       "      <td>43.274765</td>\n",
       "      <td>36.410713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>FRB20190701D</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>112.10</td>\n",
       "      <td>66.70</td>\n",
       "      <td>149.28</td>\n",
       "      <td>28.38</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>934.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>933.36290</td>\n",
       "      <td>877.4</td>\n",
       "      <td>879.4</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>1.33</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>6.49</td>\n",
       "      <td>-20.90</td>\n",
       "      <td>651.8</td>\n",
       "      <td>400.2</td>\n",
       "      <td>467.6</td>\n",
       "      <td>358566.724</td>\n",
       "      <td>354457</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900089</td>\n",
       "      <td>478.062518</td>\n",
       "      <td>251.6</td>\n",
       "      <td>0.736807</td>\n",
       "      <td>9.045763e+40</td>\n",
       "      <td>2.658107e+43</td>\n",
       "      <td>1.602564e+35</td>\n",
       "      <td>2.970051</td>\n",
       "      <td>2.970765</td>\n",
       "      <td>2.943198</td>\n",
       "      <td>2.944186</td>\n",
       "      <td>-2.053057</td>\n",
       "      <td>-2.815309</td>\n",
       "      <td>0.123852</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>-2.853872</td>\n",
       "      <td>2.814114</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.669875</td>\n",
       "      <td>2.679485</td>\n",
       "      <td>-0.045714</td>\n",
       "      <td>-0.132646</td>\n",
       "      <td>40.956445</td>\n",
       "      <td>43.424572</td>\n",
       "      <td>35.204815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>FRB20190701E</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>138.57</td>\n",
       "      <td>61.71</td>\n",
       "      <td>153.27</td>\n",
       "      <td>40.37</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>888.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>890.47710</td>\n",
       "      <td>848.1</td>\n",
       "      <td>857.0</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>800.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>410.3</td>\n",
       "      <td>359241.191</td>\n",
       "      <td>356889</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867410</td>\n",
       "      <td>746.963883</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.224910</td>\n",
       "      <td>1.715152e+40</td>\n",
       "      <td>1.088983e+43</td>\n",
       "      <td>8.899385e+35</td>\n",
       "      <td>2.949623</td>\n",
       "      <td>2.948413</td>\n",
       "      <td>2.928447</td>\n",
       "      <td>2.932981</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-3.173925</td>\n",
       "      <td>-0.167491</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>-3.376751</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.613102</td>\n",
       "      <td>2.873300</td>\n",
       "      <td>-0.061776</td>\n",
       "      <td>-0.647990</td>\n",
       "      <td>40.234303</td>\n",
       "      <td>43.037021</td>\n",
       "      <td>35.949360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tns_name    previous_name repeater_name      ra    dec      gl  \\\n",
       "0    FRB20180725A  180725.J0613+67         -9999   93.42  67.07  147.29   \n",
       "1    FRB20180727A  180727.J1311+26         -9999  197.72  26.42   24.76   \n",
       "2    FRB20180729A  180729.J1316+55         -9999  199.40  55.58  115.26   \n",
       "3    FRB20180729B  180729.J0558+56         -9999   89.93  56.50  156.90   \n",
       "4    FRB20180730A  180730.J0353+87         -9999   57.39  87.19  125.11   \n",
       "..            ...              ...           ...     ...    ...     ...   \n",
       "589  FRB20190701A            -9999         -9999  277.47  59.04   88.29   \n",
       "590  FRB20190701B            -9999         -9999  302.93  80.18  112.88   \n",
       "591  FRB20190701C            -9999         -9999   96.36  81.63  132.18   \n",
       "592  FRB20190701D            -9999         -9999  112.10  66.70  149.28   \n",
       "593  FRB20190701E            -9999         -9999  138.57  61.71  153.27   \n",
       "\n",
       "        gb  exp_up  exp_low  bonsai_snr  bonsai_dm  snr_fitb    dm_fitb  \\\n",
       "0    21.29    30.0  -9999.0        19.2      716.6      33.2  715.80930   \n",
       "1    85.60    10.4  -9999.0        10.4      642.1      12.2  642.13400   \n",
       "2    61.16    21.0  -9999.0        32.0      108.4     206.6  109.59418   \n",
       "3    15.68    21.0  -9999.0        12.4      318.6      22.0  317.22350   \n",
       "4    25.11   270.0    214.0        69.5      849.2      89.8  848.90410   \n",
       "..     ...     ...      ...         ...        ...       ...        ...   \n",
       "589  25.72    23.0  -9999.0        12.1      635.7      14.6  637.09340   \n",
       "590  23.40    69.0     70.0        15.0      748.9      17.5  749.11400   \n",
       "591  25.88    82.0     82.0        11.5      972.1      16.8  974.19500   \n",
       "592  28.38    34.0  -9999.0        34.4      934.9      44.8  933.36290   \n",
       "593  40.37    15.0  -9999.0        15.2      888.0      16.7  890.47710   \n",
       "\n",
       "     dm_exc_ne2001  dm_exc_ymw16  bc_width  scat_time   flux  fluence  \\\n",
       "0            644.2         635.4   0.00295   0.001100   1.70     4.10   \n",
       "1            620.9         622.4   0.00295   0.001700   0.58     2.31   \n",
       "2             78.8          86.8   0.00098   0.000157  11.70    17.00   \n",
       "3            223.2         198.8   0.00197   0.000660   0.92     1.20   \n",
       "4            789.7         790.5   0.00492   0.002073   5.20    27.00   \n",
       "..             ...           ...       ...        ...    ...      ...   \n",
       "589          582.8         587.8   0.00197   0.000720   1.26     1.70   \n",
       "590          687.6         688.1   0.00295   0.000340   1.10     1.90   \n",
       "591          915.8         916.6   0.00197   0.001800   0.88     2.50   \n",
       "592          877.4         879.4   0.00885   0.001530   1.33     8.60   \n",
       "593          848.1         857.0   0.00295   0.000670   0.68     2.00   \n",
       "\n",
       "     sub_num  width_fitb  sp_idx  sp_run  high_freq  low_freq  peak_freq  \\\n",
       "0          0    0.000296   38.20  -45.80      760.1     485.3      607.4   \n",
       "1          0    0.001390    3.80   -9.20      800.2     400.2      493.3   \n",
       "2          0    0.000100   16.46  -30.21      692.7     400.2      525.6   \n",
       "3          0    0.000314   14.50  -14.60      800.2     441.8      657.5   \n",
       "4          0    0.000468    4.27  -11.31      759.2     400.2      483.5   \n",
       "..       ...         ...     ...     ...        ...       ...        ...   \n",
       "589        0    0.000608   -1.10    3.30      800.2     400.2      800.2   \n",
       "590        0    0.000630    3.90  -11.80      732.8     400.2      471.5   \n",
       "591        0    0.001440   46.20 -211.00      495.5     402.2      446.4   \n",
       "592        0    0.001400    6.49  -20.90      651.8     400.2      467.6   \n",
       "593        0    0.000420    0.30   -5.10      800.2     400.2      410.3   \n",
       "\n",
       "         chi_sq     dof  flag_frac  excluded_flag previous_rp_name  \\\n",
       "0    371857.954  371481      0.403              1            -9999   \n",
       "1    382969.318  381818      0.387              1            -9999   \n",
       "2    264732.041  186953      0.399              1            -9999   \n",
       "3    425139.488  421337      0.323              1            -9999   \n",
       "4    429165.844  417689      0.329              1            -9999   \n",
       "..          ...     ...        ...            ...              ...   \n",
       "589  341779.300  341690      0.451              0            -9999   \n",
       "590  329229.311  330137      0.470              0            -9999   \n",
       "591  285697.192  286362      0.540              0            -9999   \n",
       "592  358566.724  354457      0.431              0            -9999   \n",
       "593  359241.191  356889      0.427              0            -9999   \n",
       "\n",
       "     is_repeater  redshift   fre_width  fre_width_ob  in_duration  \\\n",
       "0              0  0.640740  450.875425         274.8     0.180406   \n",
       "1              0  0.614818  645.927163         400.0     0.860778   \n",
       "2              0  0.002248  293.157605         292.5     0.099776   \n",
       "3              0  0.157566  414.871625         358.4     0.271259   \n",
       "4              0  0.802405  647.063272         359.0     0.259653   \n",
       "..           ...       ...         ...           ...          ...   \n",
       "589            0  0.572362  628.944866         400.0     0.386679   \n",
       "590            0  0.688973  561.752466         332.6     0.373008   \n",
       "591            0  0.943004  181.282298          93.3     0.741120   \n",
       "592            0  0.900089  478.062518         251.6     0.736807   \n",
       "593            0  0.867410  746.963883         400.0     0.224910   \n",
       "\n",
       "           energy    luminosity           T_B  log_dm_fitb  log_bonsai_dm  \\\n",
       "0    2.827944e+40  1.923870e+43  5.515622e+35     2.854797       2.855277   \n",
       "1    1.189571e+40  4.823143e+42  2.622746e+35     2.807626       2.807603   \n",
       "2    1.070358e+36  7.383140e+38  4.845901e+32     2.039787       2.035029   \n",
       "3    4.966122e+38  4.407270e+41  3.166148e+34     2.501365       2.503246   \n",
       "4    2.335510e+41  8.107252e+43  1.508095e+36     2.928859       2.929010   \n",
       "..            ...           ...           ...          ...            ...   \n",
       "589  1.226913e+40  1.429842e+43  4.195023e+35     2.804203       2.803252   \n",
       "590  1.178856e+40  1.152717e+43  6.863375e+35     2.874548       2.874424   \n",
       "591  2.752633e+40  1.882629e+43  2.574619e+36     2.988646       2.987711   \n",
       "592  9.045763e+40  2.658107e+43  1.602564e+35     2.970051       2.970765   \n",
       "593  1.715152e+40  1.088983e+43  8.899385e+35     2.949623       2.948413   \n",
       "\n",
       "     log_dm_exc_ne2001  log_dm_exc_ymw16  log_bc_width  log_scat_time  \\\n",
       "0             2.809021          2.803047     -2.530178      -2.958607   \n",
       "1             2.793022          2.794070     -2.530178      -2.769551   \n",
       "2             1.896526          1.938520     -3.008774      -3.802995   \n",
       "3             2.348694          2.298416     -2.705534      -3.180456   \n",
       "4             2.897462          2.897902     -2.308035      -2.683401   \n",
       "..                 ...               ...           ...            ...   \n",
       "589           2.765520          2.769230     -2.705534      -3.142668   \n",
       "590           2.837336          2.837652     -2.530178      -3.468521   \n",
       "591           2.961801          2.962180     -2.705534      -2.744727   \n",
       "592           2.943198          2.944186     -2.053057      -2.815309   \n",
       "593           2.928447          2.932981     -2.530178      -3.173925   \n",
       "\n",
       "     log_flux  log_fluence  log_width_fitb  log_high_freq  log_low_freq  \\\n",
       "0    0.230449     0.612784       -3.528708       2.880871      2.686010   \n",
       "1   -0.236572     0.363612       -2.856985       2.903199      2.602277   \n",
       "2    1.068186     1.230449       -4.000000       2.840545      2.602277   \n",
       "3   -0.036212     0.079181       -3.503070       2.903199      2.645226   \n",
       "4    0.716003     1.431364       -3.329754       2.880356      2.602277   \n",
       "..        ...          ...             ...            ...           ...   \n",
       "589  0.100371     0.230449       -3.216096       2.903199      2.602277   \n",
       "590  0.041393     0.278754       -3.200659       2.864985      2.602277   \n",
       "591 -0.055517     0.397940       -2.841638       2.695044      2.604442   \n",
       "592  0.123852     0.934498       -2.853872       2.814114      2.602277   \n",
       "593 -0.167491     0.301030       -3.376751       2.903199      2.602277   \n",
       "\n",
       "     log_peak_freq  log_fre_width  log_redshift  log_in_duration  log_energy  \\\n",
       "0         2.783475       2.654057     -0.193318        -0.743748   40.451471   \n",
       "1         2.693111       2.810184     -0.211253        -0.065109   40.075391   \n",
       "2         2.720655       2.467101     -2.648161        -1.000975   36.029529   \n",
       "3         2.817896       2.617914     -0.802538        -0.566616   38.696017   \n",
       "4         2.684396       2.810947     -0.095607        -0.585606   41.368382   \n",
       "..             ...            ...           ...              ...         ...   \n",
       "589       2.903199       2.798613     -0.242329        -0.412649   40.088814   \n",
       "590       2.673482       2.749545     -0.161798        -0.428282   40.071461   \n",
       "591       2.649724       2.258355     -0.025486        -0.130111   40.439748   \n",
       "592       2.669875       2.679485     -0.045714        -0.132646   40.956445   \n",
       "593       2.613102       2.873300     -0.061776        -0.647990   40.234303   \n",
       "\n",
       "     log_luminosity    log_T_B  \n",
       "0         43.284176  35.741595  \n",
       "1         42.683330  35.418756  \n",
       "2         38.868241  32.685375  \n",
       "3         41.644170  34.500531  \n",
       "4         43.908874  36.178429  \n",
       "..              ...        ...  \n",
       "589       43.155288  35.622734  \n",
       "590       43.061723  35.836538  \n",
       "591       43.274765  36.410713  \n",
       "592       43.424572  35.204815  \n",
       "593       43.037021  35.949360  \n",
       "\n",
       "[594 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/features_extracted/chime_frb_catalog_2021.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "FEATURES = [\n",
    "    \"ra\",\n",
    "    # \"dec\",\n",
    "    \"snr_fitb\",\n",
    "    \"log_dm_exc_ymw16\",\n",
    "    # \"log_dm_exc_ne2001\",\n",
    "    \"log_bc_width\",\n",
    "    \"log_flux\",\n",
    "    \"log_fluence\",\n",
    "    \"sp_idx\",\n",
    "    \"sp_run\",\n",
    "    \"log_in_duration\",\n",
    "    \"log_peak_freq\",\n",
    "    \"log_fre_width\",\n",
    "    \"log_T_B\",\n",
    "    \"log_energy\",\n",
    "    'log_luminosity'\n",
    "]\n",
    "FEATURE_LABELS = [\n",
    "    \"Right Ascension\",\n",
    "    # \"Declination\",  # CHIME reports that source density is high due to the long exposure near the North Celestial Pole, so repeater identification is more difficult at higher declinations than lower ones\n",
    "    \"SNR (fitburst)\",\n",
    "    \"Excess DM (YMW16)\",\n",
    "    # \"Excess DM (NE2001)\",  # We choose YMW16 instead of NE2001\n",
    "    \"Boxcar width\",\n",
    "    \"Flux\",\n",
    "    \"Fluence\",\n",
    "    \"Spectral index\",\n",
    "    \"Spectral running\",\n",
    "    \"Rest-frame width\",\n",
    "    \"Peak frequency\",\n",
    "    \"Frequency width\",\n",
    "    \"Brightness temperature\",\n",
    "    \"Burst energy\",\n",
    "    'Luminosity' # Correlated to burst energy and excess DM\n",
    "]\n",
    "X = df[FEATURES]\n",
    "y = df[\"is_repeater\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import get_subburst_preserved_train_test, lee_liu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "X = df[FEATURES]\n",
    "y = df[\"is_repeater\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = get_subburst_preserved_train_test(\n",
    "    original_df=df, X=X, y=y, test_size=0.2\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PU Classifier Optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from pulearn import ElkanotoPuClassifier, WeightedElkanotoPuClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As determined in the previous notebook\n",
    "# BASE_CLASSIFIERS = [\"SVM\", \"Logistic Regression\", \"LGBM\"]\n",
    "BASE_CLASSIFIERS = [\"LDA\", \"Logistic Regression\", \"SVM\"]\n",
    "CALIBRATED_CLASSIFIERS = [\"Logistic Regression\", \"LDA\"]\n",
    "NUM_TRIALS = 100\n",
    "optimised_models = []\n",
    "models_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "def best_base_classifier(clf_name):\n",
    "    match clf_name:\n",
    "        case \"Decision Tree\":\n",
    "            return DecisionTreeClassifier(\n",
    "                min_samples_split=15,\n",
    "                min_samples_leaf=3,\n",
    "                criterion=\"entropy\",\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"Random Forest\":\n",
    "            return RandomForestClassifier(\n",
    "                n_estimators=218,\n",
    "                min_samples_split=31,\n",
    "                min_samples_leaf=24,\n",
    "                criterion=\"gini\",\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"SVM\":\n",
    "            return SVC(\n",
    "                C=8.471801418819979,\n",
    "                degree=5,\n",
    "                kernel=\"linear\",  # fix to linear so we can access coefficients later\n",
    "                probability=True,\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"AdaBoost\":\n",
    "            return AdaBoostClassifier(\n",
    "                n_estimators=157,\n",
    "                learning_rate=0.546,\n",
    "                algorithm=\"SAMME.R\",\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"LGBM\":\n",
    "            return LGBMClassifier(\n",
    "                n_estimators=480,\n",
    "                learning_rate=0.07799402628373488,\n",
    "                subsample=0.10679258738466368,\n",
    "                colsample_bytree=0.9595824521352425,\n",
    "                random_state=RANDOM_SEED,\n",
    "                verbosity=-1,\n",
    "            )\n",
    "        case \"XGBoost\":\n",
    "            return xgb.XGBClassifier(\n",
    "                n_estimators=426,\n",
    "                eta=0.649963516505147,\n",
    "                gamma=0.05081231511820061,\n",
    "                min_child_weight=9.639798532691014,\n",
    "                max_delta_step=9.378914999779363,\n",
    "                max_leaves=168,\n",
    "                max_bin=123,\n",
    "                subsample=0.5353966969732,\n",
    "                colsample_bytree=0.3887651607578353,\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"Logistic Regression\":\n",
    "            return LogisticRegression(\n",
    "                tol=5.6115164153345e-05,\n",
    "                C=63.512210106407046,\n",
    "                solver=\"liblinear\",\n",
    "                max_iter=162,\n",
    "                random_state=RANDOM_SEED,\n",
    "            )\n",
    "        case \"LDA\":\n",
    "            return LinearDiscriminantAnalysis(\n",
    "                solver=\"lsqr\",\n",
    "                store_covariance=True,\n",
    "                tol=2.0511104188433963e-05\n",
    "            )\n",
    "\n",
    "\n",
    "# def build_optimised_model(cleaned_params, best_clf_option):\n",
    "#     match best_clf_option:\n",
    "#         case \"Decision Tree\":\n",
    "#             return DecisionTreeClassifier(**cleaned_params, random_state=RANDOM_SEED)\n",
    "#         case \"Random Forest\":\n",
    "#             return RandomForestClassifier(**cleaned_params, random_state=RANDOM_SEED)\n",
    "#         case \"SVM\":\n",
    "#             return SVC(**cleaned_params, probability=True, random_state=RANDOM_SEED)\n",
    "#         case \"AdaBoost\":\n",
    "#             return AdaBoostClassifier(**cleaned_params, random_state=RANDOM_SEED)\n",
    "#         case \"LGBM\":\n",
    "#             return LGBMClassifier(\n",
    "#                 **cleaned_params, random_state=RANDOM_SEED, verbosity=-1\n",
    "#             )\n",
    "#         case \"XGBoost\":\n",
    "#             return xgb.XGBClassifier(**cleaned_params, random_state=RANDOM_SEED)\n",
    "#         case \"Logistic Regression\":\n",
    "#             cleaned_params[\"solver\"] = cleaned_params.pop(\"solver__lr\")\n",
    "#             return LogisticRegression(**cleaned_params, random_state=RANDOM_SEED)\n",
    "#         case \"LDA\":\n",
    "#             cleaned_params[\"solver\"] = cleaned_params.pop(\"solver__lda\")\n",
    "#             return LinearDiscriminantAnalysis(**cleaned_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elkanoto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def elkanoto_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    base_clf_option = trial.suggest_categorical(\"base_clf_option\", BASE_CLASSIFIERS)\n",
    "    best_classifier = best_base_classifier(base_clf_option)\n",
    "    \n",
    "    # Calibrate the classifier using Platt scaling\n",
    "    if base_clf_option not in CALIBRATED_CLASSIFIERS:\n",
    "        best_classifier = CalibratedClassifierCV(\n",
    "            best_classifier, method=\"sigmoid\", cv=10\n",
    "        )\n",
    "    classifier_obj = ElkanotoPuClassifier(\n",
    "        estimator=best_classifier,\n",
    "        hold_out_ratio=trial.suggest_float(\"hold_out_ratio\", 0.1, 0.8),\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier_obj.predict(X_val_scaled)\n",
    "    return lee_liu_score(y_known=y_val, y_pred=y_pred)\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(elkanoto_objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: best_params={'base_clf_option': 'LDA', 'hold_out_ratio': 0.6733190645078442}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_clf_option = best_params[\"base_clf_option\"]\n",
    "print(f'Best params: {best_params=}')\n",
    "best_classifier = best_base_classifier(best_clf_option)\n",
    "if best_clf_option not in CALIBRATED_CLASSIFIERS:\n",
    "    print('Calibating...')\n",
    "    best_classifier = CalibratedClassifierCV(\n",
    "        best_classifier, method=\"sigmoid\", cv=10\n",
    "    )\n",
    "optimised_elkanoto = ElkanotoPuClassifier(\n",
    "    estimator=best_classifier,\n",
    "    hold_out_ratio=best_params[\"hold_out_ratio\"],\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "optimised_models.append(optimised_elkanoto)\n",
    "models_info.append(\n",
    "    {\"model\": \"Classic Elkanoto\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Elkanoto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def weighted_elkanoto_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    base_clf_option = trial.suggest_categorical(\"base_clf_option\", BASE_CLASSIFIERS)\n",
    "    best_classifier = best_base_classifier(base_clf_option)\n",
    "    if base_clf_option not in CALIBRATED_CLASSIFIERS:\n",
    "        best_classifier = CalibratedClassifierCV(\n",
    "            best_classifier, method=\"sigmoid\", cv=10\n",
    "        )\n",
    "    classifier_obj = WeightedElkanotoPuClassifier(\n",
    "        estimator=best_classifier,\n",
    "        hold_out_ratio=trial.suggest_float(\"hold_out_ratio\", 0.1, 0.8),\n",
    "        # Cardinality of labeled and unlabeled data\n",
    "        labeled=sum(y_train == 1),\n",
    "        unlabeled=sum(y_train == 0),\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier_obj.predict(X_val_scaled)\n",
    "    return lee_liu_score(y_known=y_val, y_pred=y_pred)\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(weighted_elkanoto_objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params={'base_clf_option': 'Logistic Regression', 'hold_out_ratio': 0.38724633067903574}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(f'{best_params=}')\n",
    "best_clf_option = best_params[\"base_clf_option\"]\n",
    "best_classifier = best_base_classifier(best_clf_option)\n",
    "if best_clf_option not in CALIBRATED_CLASSIFIERS:\n",
    "    print('Calibating...')\n",
    "    best_classifier = CalibratedClassifierCV(\n",
    "        best_classifier, method=\"sigmoid\", cv=10\n",
    "    )\n",
    "optimised_welkanoto = WeightedElkanotoPuClassifier(\n",
    "    estimator=best_classifier,\n",
    "    hold_out_ratio=best_params[\"hold_out_ratio\"],\n",
    "    labeled=sum(y == 1),\n",
    "    unlabeled=sum(y == 0),\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "optimised_models.append(optimised_welkanoto)\n",
    "models_info.append(\n",
    "    {\"model\": \"Weighted Elkanoto\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulearn import BaggingPuClassifier\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def bagging_svm_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    base_clf_option = trial.suggest_categorical(\"base_clf_option\", BASE_CLASSIFIERS)\n",
    "    best_classifier = best_base_classifier(base_clf_option)\n",
    "    classifier_obj = BaggingPuClassifier(\n",
    "        base_estimator=best_classifier,\n",
    "        n_estimators=trial.suggest_int(\"num_bagged\", 25, 200),\n",
    "        max_samples=trial.suggest_float(\"max_samples\", 0.1, 1.0),\n",
    "        max_features=trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier_obj.predict(X_val_scaled)\n",
    "    return lee_liu_score(y_known=y_val, y_pred=y_pred)\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(bagging_svm_objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params={'base_clf_option': 'SVM', 'num_bagged': 156, 'max_samples': 0.6102120095432617, 'max_features': 0.9770192274652224}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "print(f'{best_params=}')\n",
    "optimised_bagging = BaggingPuClassifier(\n",
    "    base_estimator=best_base_classifier(best_params['base_clf_option']),\n",
    "    n_estimators=best_params[\"num_bagged\"],\n",
    "    max_samples= best_params[\"max_samples\"],\n",
    "    max_features=best_params[\"max_features\"],\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "optimised_models.append(optimised_bagging)\n",
    "models_info.append(\n",
    "    {\"model\": \"Bagging Classifier\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pu_modified_lr.mlr import ModifiedLogisticRegression\n",
    "\n",
    "\n",
    "def mlr_objective(trial):\n",
    "    classifier_obj = ModifiedLogisticRegression(\n",
    "        epochs=trial.suggest_int(\"epochs\", 100, 1000),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier_obj.predict(X_val_scaled)\n",
    "    return lee_liu_score(y_known=y_val, y_pred=y_pred)\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(mlr_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "optimised_mlr = ModifiedLogisticRegression(**best_params)\n",
    "optimised_models.append(optimised_mlr)\n",
    "models_info.append(\n",
    "    {\"model\": \"MLR\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_alpha(y_labels, c):\n",
    "    # As per result in Bekker et al. 2020\n",
    "    prob_labelled = sum(y_labels == 1) / len(y_labels)\n",
    "    alpha = prob_labelled / c   \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PUExtraTrees.trees import PUExtraTrees\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def puet_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = PUExtraTrees(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 25, 200),\n",
    "        risk_estimator=trial.suggest_categorical(\"risk_estimator\", [\"nnPU\", \"uPU\"]),\n",
    "        loss=trial.suggest_categorical(\"loss\", [\"quadratic\", \"logistic\"]),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"all\"]),\n",
    "        max_candidates=trial.suggest_int(\"max_candidates\", 1, 10),\n",
    "    )\n",
    "\n",
    "    optimised_elkanoto.fit(X_train_scaled, y_train)\n",
    "    elkan_c = optimised_elkanoto.c\n",
    "    elkan_alpha = c_to_alpha(y, elkan_c)\n",
    "\n",
    "    classifier_obj.fit(X_train_scaled, y_train, alpha=elkan_alpha)\n",
    "    y_pred = classifier_obj.predict(X_val_scaled)\n",
    "    return lee_liu_score(y_known=y_val, y_pred=y_pred)\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(puet_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "optimised = PUExtraTrees(**best_params)\n",
    "optimised_models.append(optimised)\n",
    "models_info.append(\n",
    "    {\"model\": \"PUExtraTrees\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>ll_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Elkanoto</td>\n",
       "      <td>{'base_clf_option': 'LDA', 'hold_out_ratio': 0...</td>\n",
       "      <td>4.823748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUExtraTrees</td>\n",
       "      <td>{'n_estimators': 191, 'risk_estimator': 'uPU',...</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>{'base_clf_option': 'SVM', 'num_bagged': 156, ...</td>\n",
       "      <td>4.353432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLR</td>\n",
       "      <td>{'epochs': 240, 'learning_rate': 0.01568385258...</td>\n",
       "      <td>4.093294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted Elkanoto</td>\n",
       "      <td>{'base_clf_option': 'Logistic Regression', 'ho...</td>\n",
       "      <td>3.078947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                             params  \\\n",
       "0    Classic Elkanoto  {'base_clf_option': 'LDA', 'hold_out_ratio': 0...   \n",
       "4       PUExtraTrees  {'n_estimators': 191, 'risk_estimator': 'uPU',...   \n",
       "2  Bagging Classifier  {'base_clf_option': 'SVM', 'num_bagged': 156, ...   \n",
       "3                 MLR  {'epochs': 240, 'learning_rate': 0.01568385258...   \n",
       "1   Weighted Elkanoto  {'base_clf_option': 'Logistic Regression', 'ho...   \n",
       "\n",
       "   ll_score  \n",
       "0  4.823748  \n",
       "4  4.500000  \n",
       "2  4.353432  \n",
       "3  4.093294  \n",
       "1  3.078947  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(models_info)\n",
    "models_df.sort_values(\"ll_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ElkanotoPuClassifier\n",
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n",
      "\n",
      "\n",
      "Training WeightedElkanotoPuClassifier\n",
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n",
      "\n",
      "\n",
      "Training BaggingPuClassifier\n",
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n",
      "\n",
      "\n",
      "Training ModifiedLogisticRegression\n",
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n",
      "\n",
      "\n",
      "Training PUExtraTrees\n",
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rough sanity check performance of models on full dataset\n",
    "import time\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "models_fittimes = [[] for _ in range(len(optimised_models))]\n",
    "models_recalls = [[] for _ in range(len(optimised_models))]\n",
    "models_llscores = [[] for _ in range(len(optimised_models))]\n",
    "models_frac_pos = [[] for _ in range(len(optimised_models))]\n",
    "\n",
    "for i, model in enumerate(optimised_models):\n",
    "    print(f\"Training {model.__class__.__name__}\")\n",
    "    for j in range(1000):\n",
    "        if j % 100 == 0: print(f'Trial {j}')\n",
    "        X_train, X_val, y_train,y_val_ = get_subburst_preserved_train_test(\n",
    "        original_df=df, X=X, y=y, test_size=0.2\n",
    "        )\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_val = X_val.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        y_val = y_val_.reset_index(drop=True)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        start = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        end = time.time()\n",
    "        models_fittimes[i].append(end - start)\n",
    "\n",
    "        predictions = model.predict(X_val_scaled)\n",
    "        recall = recall_score(y_val, predictions)\n",
    "        ll_score = lee_liu_score(y_val, predictions)\n",
    "        frac_pos = np.mean(predictions)\n",
    "        \n",
    "        models_recalls[i].append(recall)\n",
    "        models_llscores[i].append(ll_score)\n",
    "        models_frac_pos[i].append(frac_pos)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>ll_score</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>llscore_mean</th>\n",
       "      <th>llscore_std</th>\n",
       "      <th>frac_pos_mean</th>\n",
       "      <th>frac_pos_std</th>\n",
       "      <th>fittime_mean</th>\n",
       "      <th>fittime_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>{'base_clf_option': 'SVM', 'num_bagged': 156, ...</td>\n",
       "      <td>4.353432</td>\n",
       "      <td>0.768886</td>\n",
       "      <td>0.108086</td>\n",
       "      <td>3.827464</td>\n",
       "      <td>0.743272</td>\n",
       "      <td>0.158227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.773127</td>\n",
       "      <td>35.515218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLR</td>\n",
       "      <td>{'epochs': 240, 'learning_rate': 0.01568385258...</td>\n",
       "      <td>4.093294</td>\n",
       "      <td>0.690148</td>\n",
       "      <td>0.131132</td>\n",
       "      <td>3.770481</td>\n",
       "      <td>0.788244</td>\n",
       "      <td>0.129518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.229824</td>\n",
       "      <td>0.039186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Elkanoto</td>\n",
       "      <td>{'base_clf_option': 'LDA', 'hold_out_ratio': 0...</td>\n",
       "      <td>4.823748</td>\n",
       "      <td>0.697638</td>\n",
       "      <td>0.140524</td>\n",
       "      <td>3.667550</td>\n",
       "      <td>0.871950</td>\n",
       "      <td>0.136433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUExtraTrees</td>\n",
       "      <td>{'n_estimators': 191, 'risk_estimator': 'uPU',...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>3.585413</td>\n",
       "      <td>0.673606</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.311885</td>\n",
       "      <td>0.080238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted Elkanoto</td>\n",
       "      <td>{'base_clf_option': 'Logistic Regression', 'ho...</td>\n",
       "      <td>3.078947</td>\n",
       "      <td>0.896357</td>\n",
       "      <td>0.123922</td>\n",
       "      <td>3.011100</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                                             params  \\\n",
       "2  Bagging Classifier  {'base_clf_option': 'SVM', 'num_bagged': 156, ...   \n",
       "3                 MLR  {'epochs': 240, 'learning_rate': 0.01568385258...   \n",
       "0    Classic Elkanoto  {'base_clf_option': 'LDA', 'hold_out_ratio': 0...   \n",
       "4       PUExtraTrees  {'n_estimators': 191, 'risk_estimator': 'uPU',...   \n",
       "1   Weighted Elkanoto  {'base_clf_option': 'Logistic Regression', 'ho...   \n",
       "\n",
       "   ll_score  recall_mean  recall_std  llscore_mean  llscore_std  \\\n",
       "2  4.353432     0.768886    0.108086      3.827464     0.743272   \n",
       "3  4.093294     0.690148    0.131132      3.770481     0.788244   \n",
       "0  4.823748     0.697638    0.140524      3.667550     0.871950   \n",
       "4  4.500000     0.826233    0.092694      3.585413     0.673606   \n",
       "1  3.078947     0.896357    0.123922      3.011100     0.914396   \n",
       "\n",
       "   frac_pos_mean  frac_pos_std  fittime_mean  fittime_std  \n",
       "2       0.158227           0.0      3.773127    35.515218  \n",
       "3       0.129518           0.0      1.229824     0.039186  \n",
       "0       0.136433           0.0      0.000880     0.000158  \n",
       "4       0.194876           0.0      1.311885     0.080238  \n",
       "1       0.316751           0.0      0.001365     0.000216  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_recalls_mean = [np.mean(recalls) for recalls in models_recalls]\n",
    "models_recalls_std = [np.std(recalls) for recalls in models_recalls]\n",
    "models_llscores_mean = [np.mean(llscores) for llscores in models_llscores]\n",
    "models_llscores_std = [np.std(llscores) for llscores in models_llscores]\n",
    "models_frac_pos = [np.mean(frac_pos) for frac_pos in models_frac_pos]\n",
    "models_frac_pos_std = [np.std(frac_pos) for frac_pos in models_frac_pos]\n",
    "models_fittimes_mean = [np.mean(fittimes) for fittimes in models_fittimes]\n",
    "models_fittimes_std = [np.std(fittimes) for fittimes in models_fittimes]\n",
    "\n",
    "models_df[\"recall_mean\"] = models_recalls_mean\n",
    "models_df[\"recall_std\"] = models_recalls_std\n",
    "models_df[\"llscore_mean\"] = models_llscores_mean\n",
    "models_df[\"llscore_std\"] = models_llscores_std\n",
    "models_df[\"frac_pos_mean\"] = models_frac_pos\n",
    "models_df[\"frac_pos_std\"] = models_frac_pos_std\n",
    "models_df[\"fittime_mean\"] = models_fittimes_mean\n",
    "models_df[\"fittime_std\"] = models_fittimes_std\n",
    "\n",
    "\n",
    "models_df.sort_values(\"llscore_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeater Candidate Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "predictions = {}\n",
    "\n",
    "import shap\n",
    "\n",
    "\"\"\"\n",
    "1. Train each model 1000 times\n",
    "2. For every trial, run predictions for every FRB in the dataset. If it is predicted as a repeater by 3 or more models, increment its counter by 1\n",
    "3. When the trials are done, filter the list of repeater candidates to those which were identified 100 times\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "MIN_VOTES_FOR_REPEATER_CANDIDATE = 3 # out of 5\n",
    "NUM_ITERATIONS = 1000\n",
    "\n",
    "# For ordering of SHAP figures\n",
    "order = FEATURES\n",
    "cols_nums = {col: i for i, col in enumerate(X.columns)}\n",
    "order = list(map(cols_nums.get, order))\n",
    "\n",
    "explainers = []\n",
    "models_shap_values = []\n",
    "\n",
    "all_priors = []\n",
    "\n",
    "for i in range(NUM_ITERATIONS):\n",
    "    # print(f'Trial {i}')\n",
    "\n",
    "    X_train, _, y_train, _ = get_subburst_preserved_train_test(\n",
    "        original_df=df, X=X, y=y, test_size=0.2\n",
    "    )\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    model_names = []\n",
    "    models_predictions = []\n",
    "    round_priors = []\n",
    "\n",
    "    for optimised_model in optimised_models:\n",
    "        model_name = optimised_model.__class__.__name__\n",
    "        model_names.append(model_name)\n",
    "\n",
    "        # PUExtraTrees must be after all three of these other classifiers in `optimised_models` for this to work!\n",
    "        if model_name != \"PUExtraTrees\":\n",
    "            optimised_model.fit(X_train_scaled, y_train)\n",
    "            if model_name == \"ElkanotoPuClassifier\":\n",
    "                c = optimised_model.c\n",
    "                alpha = c_to_alpha(y_train, c)\n",
    "                round_priors.append(alpha)\n",
    "            elif model_name == \"WeightedElkanotoPuClassifier\":\n",
    "                c = optimised_model.c\n",
    "                alpha = c_to_alpha(y_train, c)\n",
    "                round_priors.append(alpha)\n",
    "            elif model_name == \"ModifiedLogisticRegression\":\n",
    "                c = optimised_model.c_hat\n",
    "                alpha = c_to_alpha(y_train, c)\n",
    "                round_priors.append(alpha)\n",
    "        else:\n",
    "            mean_alpha = round_priors[1] # we only want alpha from elkanoto\n",
    "            optimised_model.fit(X_train_scaled, y_train, alpha=mean_alpha)\n",
    "        all_priors.append(round_priors)\n",
    "        \n",
    "        # Get predictions to identify potential FRB repeater candidates\n",
    "        preds = optimised_model.predict(X_scaled)\n",
    "        models_predictions.append(preds)\n",
    "\n",
    "        if i == NUM_ITERATIONS - 1:\n",
    "            explainer = shap.Explainer(optimised_model.predict, X_scaled)\n",
    "            explainer.feature_names = FEATURE_LABELS\n",
    "            explainers.append(explainer)\n",
    "            shap_values = explainer(X_scaled)\n",
    "            models_shap_values.append(shap_values)\n",
    "\n",
    "            shap.plots.beeswarm(shap_values, max_display=len(FEATURES), order=order, show=False)\n",
    "            plt.title(f'SHAP beeswarm plot for {model_name}')\n",
    "            plt.savefig(f'./figures/puml/beeswarm_{optimised_model.__class__.__name__}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "            plt.clf()\n",
    "            shap.plots.heatmap(shap_values, max_display=len(FEATURES), feature_order=order, instance_order=shap_values.sum(1), show=False)\n",
    "            plt.title(f'SHAP heatmap for {model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./figures/puml/heatmap_{model_name}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "\n",
    "    # For every FRB in the dataset, check if it is predicted as a repeater by 4 or more models\n",
    "    for index, row in X_scaled_df.iterrows():\n",
    "        if df.iloc[index]['is_repeater'] == 1:\n",
    "            continue\n",
    "        \n",
    "        model_votes = 0\n",
    "        for model_preds in models_predictions:\n",
    "            if model_preds[index] == 1:\n",
    "                model_votes += 1\n",
    "\n",
    "        if model_votes >= MIN_VOTES_FOR_REPEATER_CANDIDATE:\n",
    "            tns_name = df['tns_name'][index]\n",
    "            sub_num = df['sub_num'][index]\n",
    "            # print(tns_name)\n",
    "            key = f'{tns_name}_{sub_num}'\n",
    "            if key not in predictions.keys():\n",
    "                predictions[key] = 1\n",
    "            else:\n",
    "                predictions[key] += 1\n",
    "            \n",
    "            if i == NUM_ITERATIONS - 1:\n",
    "                try:\n",
    "                    path = f'./figures/puml/candidate_analysis/{tns_name}_{sub_num}'\n",
    "                    if not os.path.exists(path):\n",
    "                        os.makedirs(f'./figures/puml/candidate_analysis/{tns_name}_{sub_num}')\n",
    "                    for model_num, model_shap_values in enumerate(models_shap_values):\n",
    "                        shap.plots.waterfall(model_shap_values[index], show=False)\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'./figures/puml/candidate_analysis/{tns_name}_{sub_num}/{model_names[model_num]}.png')\n",
    "                        plt.clf()\n",
    "                except Exception as e:\n",
    "                    print(f'ERROR: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priors = all_priors[:-2]\n",
    "for i, prior in enumerate(all_priors):\n",
    "    if len(prior) != 3:\n",
    "        print(i, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2319819579486149\n",
      "0.22135291988492914\n",
      "[0.16272215]\n"
     ]
    }
   ],
   "source": [
    "elkan_priors = [priors[0] for priors in all_priors]\n",
    "elkan_avg_priors = np.mean(elkan_priors, axis=0)\n",
    "welkan_priors = [priors[1] for priors in all_priors]\n",
    "welkan_avg_priors = np.mean(welkan_priors, axis=0)\n",
    "mlr_priors = [priors[2] for priors in all_priors]\n",
    "mlr_avg_priors = np.mean(mlr_priors, axis=0)\n",
    "print(f'{elkan_avg_priors}\\n{welkan_avg_priors}\\n{mlr_avg_priors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeater candidates with >0% confidence: 65\n",
      "Number of repeater candidates with >=10% confidence: 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tns_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FRB20190423B_0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FRB20190429B_0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRB20181017B_0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FRB20190422A_1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRB20190329A_0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FRB20190423B_1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRB20181231B_0</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRB20181221A_0</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRB20190112A_0</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FRB20190422A_0</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRB20190228A_0</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FRB20190527A_0</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRB20190218B_0</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB20190206A_0</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FRB20181229B_0</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRB20190128C_0</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FRB20190409B_0</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FRB20190412B_0</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FRB20190410A_0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FRB20190609A_1</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FRB20190129A_0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRB20181129B_0</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FRB20190125A_0</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FRB20181228B_0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FRB20190609A_0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB20180801A_0</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FRB20181214A_0</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FRB20190403E_0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FRB20190527A_1</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FRB20190601C_0</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FRB20190601C_1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tns_name  count\n",
       "15  FRB20190423B_0   1000\n",
       "17  FRB20190429B_0   1000\n",
       "1   FRB20181017B_0   1000\n",
       "14  FRB20190422A_1   1000\n",
       "10  FRB20190329A_0   1000\n",
       "16  FRB20190423B_1   1000\n",
       "4   FRB20181231B_0    999\n",
       "3   FRB20181221A_0    998\n",
       "5   FRB20190112A_0    989\n",
       "13  FRB20190422A_0    982\n",
       "9   FRB20190228A_0    978\n",
       "18  FRB20190527A_0    903\n",
       "8   FRB20190218B_0    873\n",
       "7   FRB20190206A_0    795\n",
       "22  FRB20181229B_0    780\n",
       "6   FRB20190128C_0    662\n",
       "11  FRB20190409B_0    637\n",
       "12  FRB20190412B_0    603\n",
       "26  FRB20190410A_0    562\n",
       "20  FRB20190609A_1    562\n",
       "24  FRB20190129A_0    533\n",
       "2   FRB20181129B_0    441\n",
       "23  FRB20190125A_0    373\n",
       "21  FRB20181228B_0    323\n",
       "19  FRB20190609A_0    298\n",
       "0   FRB20180801A_0    287\n",
       "30  FRB20181214A_0    223\n",
       "25  FRB20190403E_0    169\n",
       "27  FRB20190527A_1    163\n",
       "28  FRB20190601C_0    123\n",
       "29  FRB20190601C_1    100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame.from_dict(predictions, columns=[\"count\"], orient=\"index\")\n",
    "print(f\"Number of repeater candidates with >0% confidence: {len(predictions_df)}\")\n",
    "predictions_df = predictions_df[predictions_df[\"count\"] >= (NUM_ITERATIONS * 0.1)]\n",
    "print(f\"Number of repeater candidates with >=10% confidence: {len(predictions_df)}\")\n",
    "predictions_df[\"tns_name\"] = predictions_df.index\n",
    "predictions_df = predictions_df[[\"tns_name\", \"count\"]]\n",
    "predictions_df.reset_index(drop=True, inplace=True)\n",
    "predictions_df.sort_values(by=\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model detects 26 candidates. Of these,\n",
      "23 appear as repeater candidates in reference papers, out of a total of 64 from both papers\n",
      "19 appear as repeater candidates in the supervised paper, out of a total of 27 from the supervised paper\n",
      "Candidates from original paper not identified by us: missed_candidates=['FRB20181218C', 'FRB20190109B', 'FRB20190531C', 'FRB20181226E', 'FRB20190223A', 'FRB20190220A', 'FRB20190308C', 'FRB20180915B', 'FRB20190430A', 'FRB20190125B', 'FRB20190617B', 'FRB20190625A', 'FRB20190110C', 'FRB20190601B', 'FRB20180928A', 'FRB20190111A', 'FRB20190206B', 'FRB20180911A', 'FRB20181013E', 'FRB20190222B', 'FRB20181125A', 'FRB20181130A', 'FRB20190423A', 'FRB20190308B', 'FRB20190221A', 'FRB20190418A', 'FRB20190323D', 'FRB20180920B', 'FRB20181030E', 'FRB20190618A', 'FRB20180923A', 'FRB20180907E', 'FRB20180923C', 'FRB20190517C', 'FRB20190419A', 'FRB20181220A', 'FRB20181128C', 'FRB20190106B', 'FRB20190617A', 'FRB20190204A', 'FRB20190106A']\n",
      "New candidates identified by us: new_candidate_tns_names=['FRB20181228B', 'FRB20181129B', 'FRB20180801A']\n"
     ]
    }
   ],
   "source": [
    "from utils import SUPERVISED_PAPER_REPEATERS, REFERENCE_PAPER_REPEATERS\n",
    "\n",
    "predicted_frb_candidates = list(\n",
    "    set([tns_name[:-2] for tns_name in list(predictions_df[\"tns_name\"].values)])\n",
    ")\n",
    "all_overlap = set(REFERENCE_PAPER_REPEATERS).intersection(predicted_frb_candidates)\n",
    "supervised_overlap = set(SUPERVISED_PAPER_REPEATERS).intersection(\n",
    "    predicted_frb_candidates\n",
    ")\n",
    "\n",
    "print(f\"Our model detects {len(predicted_frb_candidates)} candidates. Of these,\")\n",
    "print(\n",
    "    f\"{len(all_overlap)} appear as repeater candidates in reference papers, out of a total of {len(REFERENCE_PAPER_REPEATERS)} from both papers\"\n",
    ")\n",
    "print(\n",
    "    f\"{len(supervised_overlap)} appear as repeater candidates in the supervised paper, out of a total of {len(SUPERVISED_PAPER_REPEATERS)} from the supervised paper\"\n",
    ")\n",
    "missed_candidates = list(\n",
    "    set(REFERENCE_PAPER_REPEATERS).difference(predicted_frb_candidates)\n",
    ")\n",
    "print(f\"Candidates from original paper not identified by us: {missed_candidates=}\")\n",
    "\n",
    "new_candidate_tns_names = list(\n",
    "    set(predicted_frb_candidates).difference(REFERENCE_PAPER_REPEATERS)\n",
    ")\n",
    "print(f\"New candidates identified by us: {new_candidate_tns_names=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tns_name</th>\n",
       "      <th>sub_num</th>\n",
       "      <th>count</th>\n",
       "      <th>is_new_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB20180801A</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FRB20181228B</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRB20181129B</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FRB20190423B</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FRB20190409B</td>\n",
       "      <td>0</td>\n",
       "      <td>637</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FRB20190601C</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FRB20190527A</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FRB20190403E</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FRB20181214A</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FRB20190609A</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FRB20190125A</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FRB20190129A</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FRB20190609A</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FRB20190410A</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FRB20190412B</td>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRB20190128C</td>\n",
       "      <td>0</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FRB20190429B</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FRB20181229B</td>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB20190206A</td>\n",
       "      <td>0</td>\n",
       "      <td>795</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRB20190218B</td>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FRB20190527A</td>\n",
       "      <td>0</td>\n",
       "      <td>903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRB20190228A</td>\n",
       "      <td>0</td>\n",
       "      <td>978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FRB20190422A</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRB20190112A</td>\n",
       "      <td>0</td>\n",
       "      <td>989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRB20181221A</td>\n",
       "      <td>0</td>\n",
       "      <td>998</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRB20181231B</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FRB20190423B</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRB20190329A</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FRB20190422A</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRB20181017B</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FRB20190601C</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tns_name  sub_num  count  is_new_candidate\n",
       "0   FRB20180801A        0    287              True\n",
       "21  FRB20181228B        0    323              True\n",
       "2   FRB20181129B        0    441              True\n",
       "15  FRB20190423B        0   1000             False\n",
       "11  FRB20190409B        0    637             False\n",
       "28  FRB20190601C        0    123             False\n",
       "27  FRB20190527A        1    163             False\n",
       "25  FRB20190403E        0    169             False\n",
       "30  FRB20181214A        0    223             False\n",
       "19  FRB20190609A        0    298             False\n",
       "23  FRB20190125A        0    373             False\n",
       "24  FRB20190129A        0    533             False\n",
       "20  FRB20190609A        1    562             False\n",
       "26  FRB20190410A        0    562             False\n",
       "12  FRB20190412B        0    603             False\n",
       "6   FRB20190128C        0    662             False\n",
       "17  FRB20190429B        0   1000             False\n",
       "22  FRB20181229B        0    780             False\n",
       "7   FRB20190206A        0    795             False\n",
       "8   FRB20190218B        0    873             False\n",
       "18  FRB20190527A        0    903             False\n",
       "9   FRB20190228A        0    978             False\n",
       "13  FRB20190422A        0    982             False\n",
       "5   FRB20190112A        0    989             False\n",
       "3   FRB20181221A        0    998             False\n",
       "4   FRB20181231B        0    999             False\n",
       "16  FRB20190423B        1   1000             False\n",
       "10  FRB20190329A        0   1000             False\n",
       "14  FRB20190422A        1   1000             False\n",
       "1   FRB20181017B        0   1000             False\n",
       "29  FRB20190601C        1    100             False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"is_new_candidate\"] = predictions_df[\"tns_name\"].apply(\n",
    "    lambda x: True if x[:-2] in new_candidate_tns_names else False\n",
    ")\n",
    "predictions_df[\"sub_num\"] = predictions_df[\"tns_name\"].apply(lambda x: int(x[-1]))\n",
    "predictions_df[\"tns_name\"] = predictions_df[\"tns_name\"].apply(lambda x: x[:-2])\n",
    "predictions_df = predictions_df[[\"tns_name\", \"sub_num\", \"count\", \"is_new_candidate\"]]\n",
    "predictions_df.sort_values(by=\"count\", ascending=False).sort_values(\n",
    "    \"is_new_candidate\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = predictions_df.copy()\n",
    "for index, row in predictions_df.iterrows():\n",
    "    tns_name = row[\"tns_name\"]\n",
    "    sub_num = row[\"sub_num\"]\n",
    "    is_new_candidate = row[\"is_new_candidate\"]\n",
    "    \n",
    "    # Visually mark new candidates wiht a *\n",
    "    if is_new_candidate:\n",
    "        display_df.loc[index, \"tns_name\"] = f'{tns_name}*'\n",
    "\n",
    "display_df = display_df[['tns_name', 'sub_num', 'count']]\n",
    "display_df.sort_values(by=['count'], ascending=False)\n",
    "display_df.to_latex('tables/3__find_candidates_puml_results_all.tex', index=False)\n",
    "\n",
    "# export the rows with is_new_candidate == True\n",
    "display_df['is_new_candidate'] = display_df['tns_name'].str.contains('\\*')\n",
    "display_df = display_df[display_df['is_new_candidate'] == True]\n",
    "display_df = display_df.drop(columns=['is_new_candidate'])\n",
    "display_df.to_latex('tables/3__find_candidates_puml_results_new.tex', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tns_name</th>\n",
       "      <th>sub_num</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>in_duration</th>\n",
       "      <th>log_dm_exc_ne2001</th>\n",
       "      <th>scat_time</th>\n",
       "      <th>sp_run</th>\n",
       "      <th>log_peak_freq</th>\n",
       "      <th>log_fre_width</th>\n",
       "      <th>log_T_B</th>\n",
       "      <th>log_energy</th>\n",
       "      <th>log_luminosity</th>\n",
       "      <th>count</th>\n",
       "      <th>is_new_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB20180801A</td>\n",
       "      <td>0</td>\n",
       "      <td>322.53</td>\n",
       "      <td>72.72</td>\n",
       "      <td>0.373432</td>\n",
       "      <td>2.752509</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>-75.5</td>\n",
       "      <td>2.774955</td>\n",
       "      <td>2.511570</td>\n",
       "      <td>34.397642</td>\n",
       "      <td>40.597390</td>\n",
       "      <td>42.936302</td>\n",
       "      <td>287</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRB20181017B</td>\n",
       "      <td>0</td>\n",
       "      <td>237.76</td>\n",
       "      <td>78.50</td>\n",
       "      <td>1.914356</td>\n",
       "      <td>2.421110</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>2.773201</td>\n",
       "      <td>2.394401</td>\n",
       "      <td>33.269974</td>\n",
       "      <td>39.627719</td>\n",
       "      <td>41.921701</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRB20181129B</td>\n",
       "      <td>0</td>\n",
       "      <td>307.56</td>\n",
       "      <td>81.32</td>\n",
       "      <td>0.279727</td>\n",
       "      <td>2.536306</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>2.745699</td>\n",
       "      <td>2.319572</td>\n",
       "      <td>35.864260</td>\n",
       "      <td>40.103427</td>\n",
       "      <td>42.842131</td>\n",
       "      <td>441</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRB20181221A</td>\n",
       "      <td>0</td>\n",
       "      <td>230.58</td>\n",
       "      <td>25.86</td>\n",
       "      <td>0.607968</td>\n",
       "      <td>2.465085</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>2.707655</td>\n",
       "      <td>2.230845</td>\n",
       "      <td>34.436639</td>\n",
       "      <td>39.647526</td>\n",
       "      <td>42.074499</td>\n",
       "      <td>998</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRB20181231B</td>\n",
       "      <td>0</td>\n",
       "      <td>128.77</td>\n",
       "      <td>55.99</td>\n",
       "      <td>0.316091</td>\n",
       "      <td>2.176959</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>2.818028</td>\n",
       "      <td>2.441788</td>\n",
       "      <td>33.365483</td>\n",
       "      <td>38.216509</td>\n",
       "      <td>40.824502</td>\n",
       "      <td>999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRB20190112A</td>\n",
       "      <td>0</td>\n",
       "      <td>257.98</td>\n",
       "      <td>61.20</td>\n",
       "      <td>1.217017</td>\n",
       "      <td>2.584105</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>-51.4</td>\n",
       "      <td>2.843669</td>\n",
       "      <td>2.501723</td>\n",
       "      <td>33.944709</td>\n",
       "      <td>40.561682</td>\n",
       "      <td>42.627843</td>\n",
       "      <td>989</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRB20190128C</td>\n",
       "      <td>0</td>\n",
       "      <td>69.80</td>\n",
       "      <td>78.94</td>\n",
       "      <td>5.232715</td>\n",
       "      <td>2.378943</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>2.691612</td>\n",
       "      <td>2.377493</td>\n",
       "      <td>32.941016</td>\n",
       "      <td>39.366376</td>\n",
       "      <td>41.517636</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB20190206A</td>\n",
       "      <td>0</td>\n",
       "      <td>244.85</td>\n",
       "      <td>9.36</td>\n",
       "      <td>0.757227</td>\n",
       "      <td>2.167022</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-65.7</td>\n",
       "      <td>2.727948</td>\n",
       "      <td>2.330090</td>\n",
       "      <td>33.079954</td>\n",
       "      <td>38.655887</td>\n",
       "      <td>40.869004</td>\n",
       "      <td>795</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRB20190218B</td>\n",
       "      <td>0</td>\n",
       "      <td>268.70</td>\n",
       "      <td>17.93</td>\n",
       "      <td>1.422016</td>\n",
       "      <td>2.668665</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>2.769377</td>\n",
       "      <td>2.523963</td>\n",
       "      <td>33.407750</td>\n",
       "      <td>40.263788</td>\n",
       "      <td>42.407660</td>\n",
       "      <td>873</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRB20190228A</td>\n",
       "      <td>0</td>\n",
       "      <td>183.48</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1.648471</td>\n",
       "      <td>2.600864</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>-51.9</td>\n",
       "      <td>2.822626</td>\n",
       "      <td>2.553071</td>\n",
       "      <td>33.154650</td>\n",
       "      <td>40.928775</td>\n",
       "      <td>42.762846</td>\n",
       "      <td>978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRB20190329A</td>\n",
       "      <td>0</td>\n",
       "      <td>65.54</td>\n",
       "      <td>73.63</td>\n",
       "      <td>1.037667</td>\n",
       "      <td>2.003461</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>-272.0</td>\n",
       "      <td>2.635785</td>\n",
       "      <td>1.868443</td>\n",
       "      <td>29.341620</td>\n",
       "      <td>35.064458</td>\n",
       "      <td>37.431188</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FRB20190409B</td>\n",
       "      <td>0</td>\n",
       "      <td>126.65</td>\n",
       "      <td>63.47</td>\n",
       "      <td>1.990835</td>\n",
       "      <td>2.376212</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>-34.1</td>\n",
       "      <td>2.736795</td>\n",
       "      <td>2.527608</td>\n",
       "      <td>32.006923</td>\n",
       "      <td>39.463969</td>\n",
       "      <td>41.292706</td>\n",
       "      <td>637</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FRB20190412B</td>\n",
       "      <td>0</td>\n",
       "      <td>285.65</td>\n",
       "      <td>19.25</td>\n",
       "      <td>6.702164</td>\n",
       "      <td>2.044932</td>\n",
       "      <td>0.015500</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.359055</td>\n",
       "      <td>30.044506</td>\n",
       "      <td>37.415575</td>\n",
       "      <td>39.147168</td>\n",
       "      <td>603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FRB20190422A</td>\n",
       "      <td>0</td>\n",
       "      <td>48.56</td>\n",
       "      <td>35.15</td>\n",
       "      <td>2.412200</td>\n",
       "      <td>2.571476</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>-46.9</td>\n",
       "      <td>2.796644</td>\n",
       "      <td>2.572135</td>\n",
       "      <td>32.683137</td>\n",
       "      <td>40.230781</td>\n",
       "      <td>42.175333</td>\n",
       "      <td>982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FRB20190422A</td>\n",
       "      <td>1</td>\n",
       "      <td>48.56</td>\n",
       "      <td>35.15</td>\n",
       "      <td>1.730491</td>\n",
       "      <td>2.571476</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>-63.7</td>\n",
       "      <td>2.786964</td>\n",
       "      <td>2.495029</td>\n",
       "      <td>32.702496</td>\n",
       "      <td>40.221102</td>\n",
       "      <td>42.165654</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FRB20190423B</td>\n",
       "      <td>0</td>\n",
       "      <td>298.58</td>\n",
       "      <td>26.19</td>\n",
       "      <td>2.482321</td>\n",
       "      <td>2.009876</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>2.730459</td>\n",
       "      <td>2.203557</td>\n",
       "      <td>29.811891</td>\n",
       "      <td>35.931427</td>\n",
       "      <td>38.027190</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FRB20190423B</td>\n",
       "      <td>1</td>\n",
       "      <td>298.58</td>\n",
       "      <td>26.19</td>\n",
       "      <td>8.473785</td>\n",
       "      <td>2.009876</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>-116.0</td>\n",
       "      <td>2.719828</td>\n",
       "      <td>2.173068</td>\n",
       "      <td>29.833152</td>\n",
       "      <td>35.920796</td>\n",
       "      <td>38.016559</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FRB20190429B</td>\n",
       "      <td>0</td>\n",
       "      <td>329.93</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.341601</td>\n",
       "      <td>2.403978</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>-910.0</td>\n",
       "      <td>2.625724</td>\n",
       "      <td>1.704515</td>\n",
       "      <td>33.121116</td>\n",
       "      <td>39.311452</td>\n",
       "      <td>41.558863</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FRB20190527A</td>\n",
       "      <td>0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>7.99</td>\n",
       "      <td>1.737460</td>\n",
       "      <td>2.741073</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>-122.0</td>\n",
       "      <td>2.685473</td>\n",
       "      <td>2.312728</td>\n",
       "      <td>32.649568</td>\n",
       "      <td>40.587738</td>\n",
       "      <td>42.442111</td>\n",
       "      <td>903</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FRB20190609A</td>\n",
       "      <td>0</td>\n",
       "      <td>345.30</td>\n",
       "      <td>87.94</td>\n",
       "      <td>0.359982</td>\n",
       "      <td>2.411956</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>2.762904</td>\n",
       "      <td>2.363409</td>\n",
       "      <td>34.621568</td>\n",
       "      <td>39.792412</td>\n",
       "      <td>42.410885</td>\n",
       "      <td>298</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FRB20190609A</td>\n",
       "      <td>1</td>\n",
       "      <td>345.30</td>\n",
       "      <td>87.94</td>\n",
       "      <td>1.766576</td>\n",
       "      <td>2.411956</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>2.778513</td>\n",
       "      <td>2.428092</td>\n",
       "      <td>34.590349</td>\n",
       "      <td>39.808022</td>\n",
       "      <td>42.426495</td>\n",
       "      <td>562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FRB20181228B</td>\n",
       "      <td>0</td>\n",
       "      <td>250.43</td>\n",
       "      <td>63.85</td>\n",
       "      <td>0.066144</td>\n",
       "      <td>2.723209</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>-353.0</td>\n",
       "      <td>2.638689</td>\n",
       "      <td>2.026468</td>\n",
       "      <td>34.758913</td>\n",
       "      <td>39.717039</td>\n",
       "      <td>42.275895</td>\n",
       "      <td>323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FRB20181229B</td>\n",
       "      <td>0</td>\n",
       "      <td>238.37</td>\n",
       "      <td>19.78</td>\n",
       "      <td>2.545968</td>\n",
       "      <td>2.555940</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>2.648848</td>\n",
       "      <td>2.189784</td>\n",
       "      <td>33.092143</td>\n",
       "      <td>39.772525</td>\n",
       "      <td>41.826064</td>\n",
       "      <td>780</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FRB20190125A</td>\n",
       "      <td>0</td>\n",
       "      <td>45.73</td>\n",
       "      <td>27.81</td>\n",
       "      <td>2.162394</td>\n",
       "      <td>2.702689</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>2.816573</td>\n",
       "      <td>2.634118</td>\n",
       "      <td>33.426823</td>\n",
       "      <td>40.038023</td>\n",
       "      <td>42.362821</td>\n",
       "      <td>373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FRB20190129A</td>\n",
       "      <td>0</td>\n",
       "      <td>45.06</td>\n",
       "      <td>21.42</td>\n",
       "      <td>0.805129</td>\n",
       "      <td>2.636187</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>-37.8</td>\n",
       "      <td>2.849849</td>\n",
       "      <td>2.540613</td>\n",
       "      <td>33.701728</td>\n",
       "      <td>40.191410</td>\n",
       "      <td>42.329849</td>\n",
       "      <td>533</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FRB20190403E</td>\n",
       "      <td>0</td>\n",
       "      <td>220.22</td>\n",
       "      <td>86.54</td>\n",
       "      <td>2.001322</td>\n",
       "      <td>2.246252</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>-36.2</td>\n",
       "      <td>2.792812</td>\n",
       "      <td>2.541617</td>\n",
       "      <td>32.813255</td>\n",
       "      <td>40.061666</td>\n",
       "      <td>41.813023</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FRB20190410A</td>\n",
       "      <td>0</td>\n",
       "      <td>263.47</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.941438</td>\n",
       "      <td>2.191730</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>2.712397</td>\n",
       "      <td>2.262254</td>\n",
       "      <td>33.178027</td>\n",
       "      <td>38.589899</td>\n",
       "      <td>41.058398</td>\n",
       "      <td>562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FRB20190527A</td>\n",
       "      <td>1</td>\n",
       "      <td>12.45</td>\n",
       "      <td>7.99</td>\n",
       "      <td>1.607313</td>\n",
       "      <td>2.741073</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>-133.0</td>\n",
       "      <td>2.652343</td>\n",
       "      <td>2.235814</td>\n",
       "      <td>32.715828</td>\n",
       "      <td>40.554608</td>\n",
       "      <td>42.408981</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FRB20190601C</td>\n",
       "      <td>0</td>\n",
       "      <td>88.52</td>\n",
       "      <td>28.47</td>\n",
       "      <td>0.581997</td>\n",
       "      <td>2.376029</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-68.8</td>\n",
       "      <td>2.713491</td>\n",
       "      <td>2.349346</td>\n",
       "      <td>34.008461</td>\n",
       "      <td>39.370964</td>\n",
       "      <td>41.798246</td>\n",
       "      <td>123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FRB20190601C</td>\n",
       "      <td>1</td>\n",
       "      <td>88.52</td>\n",
       "      <td>28.47</td>\n",
       "      <td>0.433945</td>\n",
       "      <td>2.376029</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-79.5</td>\n",
       "      <td>2.700877</td>\n",
       "      <td>2.305159</td>\n",
       "      <td>34.033689</td>\n",
       "      <td>39.358350</td>\n",
       "      <td>41.785632</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FRB20181214A</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>43.07</td>\n",
       "      <td>0.433047</td>\n",
       "      <td>2.453165</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>2.638489</td>\n",
       "      <td>2.065164</td>\n",
       "      <td>34.079702</td>\n",
       "      <td>38.391946</td>\n",
       "      <td>41.062479</td>\n",
       "      <td>223</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tns_name  sub_num      ra    dec  in_duration  log_dm_exc_ne2001  \\\n",
       "0   FRB20180801A        0  322.53  72.72     0.373432           2.752509   \n",
       "1   FRB20181017B        0  237.76  78.50     1.914356           2.421110   \n",
       "2   FRB20181129B        0  307.56  81.32     0.279727           2.536306   \n",
       "3   FRB20181221A        0  230.58  25.86     0.607968           2.465085   \n",
       "4   FRB20181231B        0  128.77  55.99     0.316091           2.176959   \n",
       "5   FRB20190112A        0  257.98  61.20     1.217017           2.584105   \n",
       "6   FRB20190128C        0   69.80  78.94     5.232715           2.378943   \n",
       "7   FRB20190206A        0  244.85   9.36     0.757227           2.167022   \n",
       "8   FRB20190218B        0  268.70  17.93     1.422016           2.668665   \n",
       "9   FRB20190228A        0  183.48  22.90     1.648471           2.600864   \n",
       "10  FRB20190329A        0   65.54  73.63     1.037667           2.003461   \n",
       "11  FRB20190409B        0  126.65  63.47     1.990835           2.376212   \n",
       "12  FRB20190412B        0  285.65  19.25     6.702164           2.044932   \n",
       "13  FRB20190422A        0   48.56  35.15     2.412200           2.571476   \n",
       "14  FRB20190422A        1   48.56  35.15     1.730491           2.571476   \n",
       "15  FRB20190423B        0  298.58  26.19     2.482321           2.009876   \n",
       "16  FRB20190423B        1  298.58  26.19     8.473785           2.009876   \n",
       "17  FRB20190429B        0  329.93   3.96     5.341601           2.403978   \n",
       "18  FRB20190527A        0   12.45   7.99     1.737460           2.741073   \n",
       "19  FRB20190609A        0  345.30  87.94     0.359982           2.411956   \n",
       "20  FRB20190609A        1  345.30  87.94     1.766576           2.411956   \n",
       "21  FRB20181228B        0  250.43  63.85     0.066144           2.723209   \n",
       "22  FRB20181229B        0  238.37  19.78     2.545968           2.555940   \n",
       "23  FRB20190125A        0   45.73  27.81     2.162394           2.702689   \n",
       "24  FRB20190129A        0   45.06  21.42     0.805129           2.636187   \n",
       "25  FRB20190403E        0  220.22  86.54     2.001322           2.246252   \n",
       "26  FRB20190410A        0  263.47  -2.37     0.941438           2.191730   \n",
       "27  FRB20190527A        1   12.45   7.99     1.607313           2.741073   \n",
       "28  FRB20190601C        0   88.52  28.47     0.581997           2.376029   \n",
       "29  FRB20190601C        1   88.52  28.47     0.433945           2.376029   \n",
       "30  FRB20181214A        0   70.00  43.07     0.433047           2.453165   \n",
       "\n",
       "    scat_time  sp_run  log_peak_freq  log_fre_width    log_T_B  log_energy  \\\n",
       "0    0.005540   -75.5       2.774955       2.511570  34.397642   40.597390   \n",
       "1    0.004300   -77.0       2.773201       2.394401  33.269974   39.627719   \n",
       "2    0.000830  -112.0       2.745699       2.319572  35.864260   40.103427   \n",
       "3    0.001323  -128.0       2.707655       2.230845  34.436639   39.647526   \n",
       "4    0.001750   -60.0       2.818028       2.441788  33.365483   38.216509   \n",
       "5    0.011010   -51.4       2.843669       2.501723  33.944709   40.561682   \n",
       "6    0.007600   -55.0       2.691612       2.377493  32.941016   39.366376   \n",
       "7    0.002740   -65.7       2.727948       2.330090  33.079954   38.655887   \n",
       "8    0.014100   -60.0       2.769377       2.523963  33.407750   40.263788   \n",
       "9    0.018910   -51.9       2.822626       2.553071  33.154650   40.928775   \n",
       "10   0.000900  -272.0       2.635785       1.868443  29.341620   35.064458   \n",
       "11   0.020900   -34.1       2.736795       2.527608  32.006923   39.463969   \n",
       "12   0.015500    -2.7       2.602277       2.359055  30.044506   37.415575   \n",
       "13   0.002700   -46.9       2.796644       2.572135  32.683137   40.230781   \n",
       "14   0.002700   -63.7       2.786964       2.495029  32.702496   40.221102   \n",
       "15   0.003000  -106.0       2.730459       2.203557  29.811891   35.931427   \n",
       "16   0.003000  -116.0       2.719828       2.173068  29.833152   35.920796   \n",
       "17   0.007800  -910.0       2.625724       1.704515  33.121116   39.311452   \n",
       "18   0.005080  -122.0       2.685473       2.312728  32.649568   40.587738   \n",
       "19   0.000500   -84.0       2.762904       2.363409  34.621568   39.792412   \n",
       "20   0.000500   -67.0       2.778513       2.428092  34.590349   39.808022   \n",
       "21   0.001159  -353.0       2.638689       2.026468  34.758913   39.717039   \n",
       "22   0.005100  -103.0       2.648848       2.189784  33.092143   39.772525   \n",
       "23   0.004100   -37.0       2.816573       2.634118  33.426823   40.038023   \n",
       "24   0.010200   -37.8       2.849849       2.540613  33.701728   40.191410   \n",
       "25   0.018200   -36.2       2.792812       2.541617  32.813255   40.061666   \n",
       "26   0.001200   -85.0       2.712397       2.262254  33.178027   38.589899   \n",
       "27   0.005080  -133.0       2.652343       2.235814  32.715828   40.554608   \n",
       "28   0.000119   -68.8       2.713491       2.349346  34.008461   39.370964   \n",
       "29   0.000119   -79.5       2.700877       2.305159  34.033689   39.358350   \n",
       "30   0.000442  -139.0       2.638489       2.065164  34.079702   38.391946   \n",
       "\n",
       "    log_luminosity  count  is_new_candidate  \n",
       "0        42.936302    287              True  \n",
       "1        41.921701   1000             False  \n",
       "2        42.842131    441              True  \n",
       "3        42.074499    998             False  \n",
       "4        40.824502    999             False  \n",
       "5        42.627843    989             False  \n",
       "6        41.517636    662             False  \n",
       "7        40.869004    795             False  \n",
       "8        42.407660    873             False  \n",
       "9        42.762846    978             False  \n",
       "10       37.431188   1000             False  \n",
       "11       41.292706    637             False  \n",
       "12       39.147168    603             False  \n",
       "13       42.175333    982             False  \n",
       "14       42.165654   1000             False  \n",
       "15       38.027190   1000             False  \n",
       "16       38.016559   1000             False  \n",
       "17       41.558863   1000             False  \n",
       "18       42.442111    903             False  \n",
       "19       42.410885    298             False  \n",
       "20       42.426495    562             False  \n",
       "21       42.275895    323              True  \n",
       "22       41.826064    780             False  \n",
       "23       42.362821    373             False  \n",
       "24       42.329849    533             False  \n",
       "25       41.813023    169             False  \n",
       "26       41.058398    562             False  \n",
       "27       42.408981    163             False  \n",
       "28       41.798246    123             False  \n",
       "29       41.785632    100             False  \n",
       "30       41.062479    223             False  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = [\n",
    "    \"ra\",\n",
    "    \"dec\",\n",
    "    \"in_duration\",\n",
    "    \"log_dm_exc_ne2001\",\n",
    "    \"scat_time\",\n",
    "    \"sp_run\",\n",
    "    \"log_peak_freq\",\n",
    "    \"log_fre_width\",\n",
    "    \"log_T_B\",\n",
    "    \"log_energy\",\n",
    "    \"log_luminosity\",\n",
    "]\n",
    "for index, row in predictions_df.iterrows():\n",
    "    tns_name = row[\"tns_name\"]\n",
    "    sub_num = row[\"sub_num\"]\n",
    "\n",
    "    # Get FRB data from the original df\n",
    "    original_df_subb_rows = df[df[\"tns_name\"] == tns_name]\n",
    "    original_df_subb_row = original_df_subb_rows[\n",
    "        original_df_subb_rows[\"sub_num\"] == sub_num\n",
    "    ]\n",
    "\n",
    "    properties_dict = {}\n",
    "    for property in properties:\n",
    "        properties_dict[property] = original_df_subb_row[property].values[0]\n",
    "\n",
    "    # Modify the row in predictions_df with the new properties as separate columns\n",
    "    for key, value in properties_dict.items():\n",
    "        predictions_df.loc[index, key] = value\n",
    "    # Move sub_num and count to the end of the columns\n",
    "predictions_df = predictions_df[\n",
    "    [\"tns_name\", \"sub_num\"] + properties + [\"count\", \"is_new_candidate\"]\n",
    "]\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
